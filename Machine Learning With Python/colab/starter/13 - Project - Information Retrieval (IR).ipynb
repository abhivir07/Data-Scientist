{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e615d705",
   "metadata": {},
   "source": [
    "<a \n",
    " href=\"https://colab.research.google.com/github/LearnPythonWithRune/MachineLearningWithPython/blob/main/colab/starter/13 - Project - Information Retrieval (IR).ipynb\"\n",
    " target=\"_parent\">\n",
    "<img \n",
    " src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
    "alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42ffed",
   "metadata": {},
   "source": [
    "# Project: Information Retrieval (IR)\n",
    "- Calculate the TF-IDF of the corpus form 'files/holmes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803e001a",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ae8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa401848",
   "metadata": {},
   "source": [
    "### Step 2: Read the corpus\n",
    "- Read all the Sherlock Holmes texts in files/holmes/\n",
    "- Create a dictionary (dict) calleds corpus\n",
    "- Use os.listdir(...) ([docs](https://docs.python.org/3/library/os.html)) to iterate over all the filenames in 'files/holmes'\n",
    "- For each filename open the file and read the content and add it to the **corpus[filename]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b211aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531566a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b4ec6ab",
   "metadata": {},
   "source": [
    "### Step 3: Tokenize the content\n",
    "- Iterate over **filename** in **corpus**\n",
    "- For each filename assign **corpus[filename]** to be the list of word (in lower) for word in word_tokenize(...) of the content of filename if word is alpha.\n",
    "    - HINT: Use list comprehension\n",
    "    - HINT: Use **.isalpha()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf670974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ed1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd72c541",
   "metadata": {},
   "source": [
    "### Step 4: Get all words\n",
    "- Create a set **words**\n",
    "    - HINT: **words = set()**\n",
    "- For each **filename** in **corpus** update the set **words** with the content\n",
    "    - HINT: apply **update(...)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5535b68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd85638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e74793c",
   "metadata": {},
   "source": [
    "### Step 5: Calculate term frequency (TF)\n",
    "- Createa empty dictionary (dict) called **tf**\n",
    "- Iterate over **filename** in **corpus**\n",
    "- For each filename add **tf[filename]** with the word frequency.\n",
    "    - HINT: Use dict comprehension with **word** in **words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54bf0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0676a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4bf275e",
   "metadata": {},
   "source": [
    "### Step 6: Calculate the inverse document frequency (IDF)\n",
    "- Create an empty dictionary called **idf**\n",
    "- Iterate **word** in **words**\n",
    "- For each **word** calculate the number of documents word is in the corpus\n",
    "    - HINT: **freq = sum(word in corpus[filename] for filename in corpus)**\n",
    "- Update **idf[word]** to be the logarithm of number of documents divided by the calcualted frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df5f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e76cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e84cef46",
   "metadata": {},
   "source": [
    "### Step 7: Calculate the Term Frequence-Inverse Document Frequency (TF-IDF)\n",
    "- Create a dictionary tfidf\n",
    "- Iterate over **filename** in **corpus**\n",
    "- For each **filename** calculate the TF-IDF for each word and add it as pairs **(word, tf-idf)**\n",
    "    - HINT: Use list comprehension **[(word, tf[filename][word] * idf[word]) for word in words]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e886e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0993c90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3694d85d",
   "metadata": {},
   "source": [
    "### Step 8: Sort the values\n",
    "- Iterate over **filename** in **corpus**\n",
    "- For each **filename** sort the values in **tfidf** by second item in reverse order\n",
    "    - HINT: Use **sorted** ([docs](https://docs.python.org/3/howto/sorting.html)) with **key=lambda x: x[1]** and **reverse=True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b7b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d8b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c17b08",
   "metadata": {},
   "source": [
    "### Step 9: Print the top five words\n",
    "- Iterate **filename** in **corpus**\n",
    "- For each **filename** print the filename and iterate over the first file elements of **tfidf[filename]** and print the **term** and **score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469b1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5cdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8fd30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
